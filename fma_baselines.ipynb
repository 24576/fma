{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# FMA: A Dataset For Music Analysis\n",
    "\n",
    "Kirell Benzi, MichaÃ«l Defferrard, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
    "\n",
    "## Baselines\n",
    "\n",
    "We explore three types of baselines:\n",
    "1. simple algorithms,\n",
    "2. state-of-the-art in genre recognition,\n",
    "3. deep Learning approaches,\n",
    "\n",
    "using different input features:\n",
    "1. raw audio,\n",
    "2. echonest features,\n",
    "3. audio features from librosa or [kapre](https://github.com/keunwoochoi/kapre).\n",
    "\n",
    "We aim at showing that given sufficient data, DL approaches can outperfom all the others without domain-specific / expert knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('..', 'fma_small')\n",
    "df = pd.read_json(os.path.join(DATA_DIR, 'fma_small.json'))\n",
    "#df = pd.read_json(os.path.join('..', 'fma_medium.json'))\n",
    "\n",
    "path = utils.build_path(df, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1 Simple classifiers on Echonest features\n",
    "\n",
    "Todo:\n",
    "* Cross-validation for hyper-parameters.\n",
    "* Dimensionality reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select features.\n",
    "#features = utils.ECHONEST_AUDIO_FEATURES + utils.ECHONEST_SOCIAL_FEATURES\n",
    "features = utils.ECHONEST_AUDIO_FEATURES\n",
    "\n",
    "# Discard songs with NaN Echonest features.\n",
    "# TODO: fix dataset.\n",
    "keep = df[features].isnull().apply(lambda x: not x.any(), axis=1)\n",
    "df = df[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pre_process(df, features, multi_label=False):\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        y = enc.fit_transform(df['top_genre'])\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        y = enc.fit_transform(df['genres'])\n",
    "    print('Genres ({}): {}'.format(len(enc.classes_), enc.classes_))\n",
    "\n",
    "    X = df[features].as_matrix()\n",
    "    \n",
    "    # Split in training, validation and testing sets.\n",
    "    train = df['train'] == True\n",
    "    y_train = y[train]\n",
    "    y_test = y[~train]\n",
    "    X_train = X[train]\n",
    "    X_test = X[~train]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.2, random_state=42)\n",
    "    print('{} training examples, {} validation examples, {} testing examples'.format(y_train.shape[0], y_val.shape[0], y_test.shape[0]))\n",
    "    print('{} features'.format(X_train.shape[1]))\n",
    "    \n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    return y_train, y_val, y_test, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.2 Single genre\n",
    "\n",
    "Maximum observed is around 38%, both on `fma_small` and `fma_medium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train, y_val, y_test, X_train, X_val, X_test = pre_process(df, features)\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(n_neighbors=200),\n",
    "    SVC(),\n",
    "    SVC(kernel=\"linear\"),\n",
    "    LinearSVC(),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(n_estimators=10),\n",
    "    MLPClassifier(max_iter=400),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    t = time.process_time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print('{:.2f}% {:.2f}s {}'.format(score*100, time.process_time()-t, type(clf).__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.3 Multiple genres\n",
    "\n",
    "Maximum observed is around 11% for `fma_small` and 7.6% for `fma_medium`.\n",
    "\n",
    "TODO:\n",
    "* Eliminate rare genres. On small only the 10 selected genres are meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train, y_val, y_test, X_train, X_val, X_test = pre_process(df, features, multi_label=True)\n",
    "\n",
    "classifiers = [\n",
    "    #LogisticRegression(),\n",
    "    OneVsRestClassifier(LogisticRegression()),\n",
    "    OneVsRestClassifier(SVC()),\n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    t = time.process_time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print('{:.2f}% {:.2f}s {}'.format(score*100, time.process_time()-t, type(clf).__name__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
